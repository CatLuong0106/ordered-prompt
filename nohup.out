2024-11-30 04:15:38.631338: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2024-11-30 04:15:38.644919: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2024-11-30 04:15:38.649033: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-11-30 04:15:38.659496: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-11-30 04:15:44.403544: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
Namespace(config='config/rte.yaml', model='llama3', seed=3, nshot=2, test_data_path='', output='/home/luongcn/mystuff/ordered-prompt/experiment/rte', generate=True, ngram=3, max_generation_length=128, temperature=0.2, do_sample=True, topk=20, train_sample_mode='')
override n-shot from 8 to 2
{'train_data_path': 'data/rte/train.jsonl', 'test_data_path': 'data/rte/dev.jsonl', 'tokenizer_path': 'meta-llama/Llama-3.2-1B-Instruct', 'n_shot': 2, 'label_mapping': {'not_entailment': 'False', 'entailment': 'True'}, 'corpus_params': {'sentence_1_str': 'sentence_1', 'sentence_2_str': 'sentence_2', 'label_str': 'label'}, 'template': "f'premise: {sentence_1}\\nhypothesis: {sentence_2}\\nprediction: {label_text}\\n\\n'", 'sample_mode': 'balance', 'sentence_pair': True, 'permutation_max_size': 24}
False
True
[22;0t]0;IPython: mystuff/ordered-promptTraceback [1;36m(most recent call last)[0m:
  File [0;32m"/home/luongcn/mystuff/ordered-prompt/main.py"[0m, line [0;32m162[0m, in [0;35m<module>[0m
    main(corpus_config=corpus_config, args=args)
  File [0;32m"/home/luongcn/mystuff/ordered-prompt/main.py"[0m, line [0;32m99[0m, in [0;35mmain[0m
    model = init_model(args)
  File [0;32m"/home/luongcn/mystuff/ordered-prompt/main.py"[0m, line [0;32m39[0m, in [0;35minit_model[0m
    model = model.to('cuda', non_blocking=True)
  File [0;32m"/home/luongcn/.local/lib/python3.9/site-packages/torch/nn/modules/module.py"[0m, line [0;32m1145[0m, in [0;35mto[0m
    return self._apply(convert)
  File [0;32m"/home/luongcn/.local/lib/python3.9/site-packages/torch/nn/modules/module.py"[0m, line [0;32m797[0m, in [0;35m_apply[0m
    module._apply(fn)
  File [0;32m"/home/luongcn/.local/lib/python3.9/site-packages/torch/nn/modules/module.py"[0m, line [0;32m797[0m, in [0;35m_apply[0m
    module._apply(fn)
  File [0;32m"/home/luongcn/.local/lib/python3.9/site-packages/torch/nn/modules/module.py"[0m, line [0;32m797[0m, in [0;35m_apply[0m
    module._apply(fn)
  File [0;32m"/home/luongcn/.local/lib/python3.9/site-packages/torch/nn/modules/module.py"[0m, line [0;32m797[0m, in [0;35m_apply[0m
    module._apply(fn)
  File [0;32m"/home/luongcn/.local/lib/python3.9/site-packages/torch/nn/modules/module.py"[0m, line [0;32m797[0m, in [0;35m_apply[0m
    module._apply(fn)
  File [0;32m"/home/luongcn/.local/lib/python3.9/site-packages/torch/nn/modules/module.py"[0m, line [0;32m797[0m, in [0;35m_apply[0m
    module._apply(fn)
  File [0;32m"/home/luongcn/.local/lib/python3.9/site-packages/torch/nn/modules/module.py"[0m, line [0;32m820[0m, in [0;35m_apply[0m
    param_applied = fn(param)
[1;36m  File [1;32m"/home/luongcn/.local/lib/python3.9/site-packages/torch/nn/modules/module.py"[1;36m, line [1;32m1143[1;36m, in [1;35mconvert[1;36m[0m
[1;33m    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)[0m
[1;31mOutOfMemoryError[0m[1;31m:[0m CUDA out of memory. Tried to allocate 64.00 MiB (GPU 0; 79.14 GiB total capacity; 4.03 GiB already allocated; 23.62 MiB free; 4.03 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

> [0;32m/home/luongcn/.local/lib/python3.9/site-packages/torch/nn/modules/module.py[0m(1143)[0;36mconvert[0;34m()[0m
[0;32m   1141 [0;31m                return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,
[0m[0;32m   1142 [0;31m                            non_blocking, memory_format=convert_to_format)
[0m[0;32m-> 1143 [0;31m            [0;32mreturn[0m [0mt[0m[0;34m.[0m[0mto[0m[0;34m([0m[0mdevice[0m[0;34m,[0m [0mdtype[0m [0;32mif[0m [0mt[0m[0;34m.[0m[0mis_floating_point[0m[0;34m([0m[0;34m)[0m [0;32mor[0m [0mt[0m[0;34m.[0m[0mis_complex[0m[0;34m([0m[0;34m)[0m [0;32melse[0m [0;32mNone[0m[0;34m,[0m [0mnon_blocking[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[0;32m   1144 [0;31m[0;34m[0m[0m
[0m[0;32m   1145 [0;31m        [0;32mreturn[0m [0mself[0m[0;34m.[0m[0m_apply[0m[0;34m([0m[0mconvert[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m
ipdb> Error in sys.excepthook:
Traceback (most recent call last):
  File "/usr/local/anaconda3/lib/python3.9/site-packages/IPython/core/ultratb.py", line 1221, in __call__
    self.debugger()
  File "/usr/local/anaconda3/lib/python3.9/site-packages/IPython/core/ultratb.py", line 1198, in debugger
    self.pdb.interaction(None, etb)
  File "/usr/local/anaconda3/lib/python3.9/site-packages/IPython/core/debugger.py", line 442, in interaction
    OldPdb.interaction(self, frame, traceback)
  File "/usr/local/anaconda3/lib/python3.9/pdb.py", line 357, in interaction
    self._cmdloop()
  File "/usr/local/anaconda3/lib/python3.9/pdb.py", line 322, in _cmdloop
    self.cmdloop()
  File "/usr/local/anaconda3/lib/python3.9/cmd.py", line 126, in cmdloop
    line = input(self.prompt)
OSError: [Errno 9] Bad file descriptor

Original exception was:
Traceback (most recent call last):
  File "/home/luongcn/mystuff/ordered-prompt/main.py", line 162, in <module>
    main(corpus_config=corpus_config, args=args)
  File "/home/luongcn/mystuff/ordered-prompt/main.py", line 99, in main
    model = init_model(args)
  File "/home/luongcn/mystuff/ordered-prompt/main.py", line 39, in init_model
    model = model.to('cuda', non_blocking=True)
  File "/home/luongcn/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1145, in to
    return self._apply(convert)
  File "/home/luongcn/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 797, in _apply
    module._apply(fn)
  File "/home/luongcn/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 797, in _apply
    module._apply(fn)
  File "/home/luongcn/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 797, in _apply
    module._apply(fn)
  [Previous line repeated 3 more times]
  File "/home/luongcn/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 820, in _apply
    param_applied = fn(param)
  File "/home/luongcn/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1143, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 64.00 MiB (GPU 0; 79.14 GiB total capacity; 4.03 GiB already allocated; 23.62 MiB free; 4.03 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
python main.py --config config/rte.yaml      --nshot 2 --model llama3 --output /home/luongcn/mystuff/ordered-prompt/experiment/rte --seed 3      --ngram 3 --generate --temperature 0.2 --topk 20 --do_sample
2024-11-30 04:16:09.367742: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2024-11-30 04:16:09.381334: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2024-11-30 04:16:09.385590: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-11-30 04:16:09.396288: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-11-30 04:16:13.290263: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
Namespace(config='config/rte.yaml', model='llama3', seed=3, nshot=2, test_data_path='', output='/home/luongcn/mystuff/ordered-prompt/experiment/rte', generate=True, ngram=5, max_generation_length=128, temperature=0.2, do_sample=True, topk=20, train_sample_mode='')
override n-shot from 8 to 2
{'train_data_path': 'data/rte/train.jsonl', 'test_data_path': 'data/rte/dev.jsonl', 'tokenizer_path': 'meta-llama/Llama-3.2-1B-Instruct', 'n_shot': 2, 'label_mapping': {'not_entailment': 'False', 'entailment': 'True'}, 'corpus_params': {'sentence_1_str': 'sentence_1', 'sentence_2_str': 'sentence_2', 'label_str': 'label'}, 'template': "f'premise: {sentence_1}\\nhypothesis: {sentence_2}\\nprediction: {label_text}\\n\\n'", 'sample_mode': 'balance', 'sentence_pair': True, 'permutation_max_size': 24}
False
True
allowed tokens <|begin_of_text|>premise: 
hypothesis: 
prediction: 

 False True
Use full permutations
train_prompts_length:  273
  0%|          | 0/128 [00:00<?, ?it/s]  1%|          | 1/128 [00:07<16:09,  7.64s/it]  2%|▏         | 2/128 [00:12<12:57,  6.17s/it]  2%|▏         | 3/128 [00:17<11:45,  5.65s/it]  3%|▎         | 4/128 [00:23<11:50,  5.73s/it]  4%|▍         | 5/128 [00:30<12:13,  5.97s/it]  5%|▍         | 6/128 [00:36<12:29,  6.14s/it]  5%|▌         | 7/128 [00:43<12:38,  6.27s/it]  6%|▋         | 8/128 [00:49<12:48,  6.41s/it]  7%|▋         | 9/128 [00:56<13:08,  6.63s/it]  8%|▊         | 10/128 [01:03<13:18,  6.77s/it]  9%|▊         | 11/128 [01:10<13:15,  6.80s/it]  9%|▉         | 12/128 [01:17<13:20,  6.90s/it] 10%|█         | 13/128 [01:25<13:31,  7.05s/it] 11%|█         | 14/128 [01:32<13:35,  7.16s/it] 12%|█▏        | 15/128 [01:39<13:28,  7.15s/it] 12%|█▎        | 16/128 [01:46<13:10,  7.06s/it] 13%|█▎        | 17/128 [01:53<13:04,  7.07s/it] 14%|█▍        | 18/128 [02:01<13:02,  7.11s/it] 15%|█▍        | 19/128 [02:08<12:58,  7.14s/it] 16%|█▌        | 20/128 [02:15<12:56,  7.19s/it] 16%|█▋        | 21/128 [02:22<12:54,  7.23s/it] 17%|█▋        | 22/128 [02:29<12:39,  7.16s/it] 18%|█▊        | 23/128 [02:35<11:41,  6.68s/it] 19%|█▉        | 24/128 [02:41<11:03,  6.38s/it] 20%|█▉        | 25/128 [02:46<10:19,  6.01s/it] 20%|██        | 26/128 [02:51<09:41,  5.71s/it] 21%|██        | 27/128 [02:55<09:02,  5.37s/it] 22%|██▏       | 28/128 [03:00<08:48,  5.28s/it] 23%|██▎       | 29/128 [03:05<08:32,  5.17s/it] 23%|██▎       | 30/128 [03:10<08:21,  5.12s/it]